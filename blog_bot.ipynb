{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-generate travel blogs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Example script to generate blogging text from nomadic matt's blog.\n",
    "\n",
    "Starting off by training a simple model with very little text\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Flatten, Dropout, TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download over a network\n",
    "# path = get_file('output.txt', origin='https://www......')\n",
    "# with io.open(path, encoding='utf-8') as f:\n",
    "#     text = f.read().lower()\n",
    "\n",
    "text = ''\n",
    "with open(\"blog.txt\", 'r') as content_file:\n",
    "    for line in content_file.readlines():\n",
    "        text += line\n",
    "        \n",
    "# text = text[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw text chars: 6654892\n",
      "total vocab: 155\n",
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '¬°', '¬£', '¬Æ', '¬∞', '¬±', '¬¥', '¬º', '¬Ω', '√Å', '√Ö', '√á', '√â', '√ç', '√é', '√ó', '√ü', '√†', '√°', '√¢', '√£', '√§', '√•', '√¶', '√ß', '√®', '√©', '√™', '√¨', '√≠', '√Ø', '√∞', '√±', '√≤', '√≥', '√¥', '√∂', '√∏', '√∫', '√ª', '√º', '√Ω', 'ƒÅ', 'ƒ´', 'ƒ±', '≈ü', '≈°', 'ÃÅ', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¶', '‚Ä≥', '‚Ç¨', '‚úì', 'üòâ', 'üôÅ', 'üôÇ']\n"
     ]
    }
   ],
   "source": [
    "def print_stats(text, chars):\n",
    "    print('Total raw text chars:', len(text))    \n",
    "    print('total vocab:', len(chars))\n",
    "    print(chars)\n",
    "    \n",
    "chars = sorted(list(set(text)))\n",
    "print_stats(text, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total vocab for this text comes to about 75 unique characters. Most of them are not required and can be removed. We shall cleanup the text to retain only ASCII characters and convert all alphabets to lowercase, which reduces the text size and brings down the vocab count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw text chars: 6614263\n",
      "total vocab: 69\n",
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "def get_ASCII_text(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+','', text)\n",
    "\n",
    "text = get_ASCII_text(text).lower()\n",
    "chars = sorted(list(set(text)))\n",
    "print_stats(text, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are some more characters that we could remove to further clean up the dataset that will reduce the vocabulary and may improve the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw text chars: 6510373\n",
      "total vocab: 57\n",
      "[' ', '!', '\"', '#', '$', '%', '(', ')', '*', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n"
     ]
    }
   ],
   "source": [
    "chars_to_remove = ['&', '[', ']', '\\\\', '^', '_', '`', '{', '}', '~', \"'\", '/', '\\n']\n",
    "\n",
    "for ch in chars_to_remove:\n",
    "    if ch in text:\n",
    "        text = text.replace(ch, '')\n",
    "        \n",
    "chars = sorted(list(set(text)))\n",
    "print_stats(text, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare data for modelling by the neural network, we cannot model the characters directly. We should first convert the characters to integers. This can be done by mapping every character to an integer. \n",
    "\n",
    "Also, when preparing the mapping of unique characters to integers, we must also create a reverse mapping that we can use to convert the integers back to characters so that we can understand the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define the training data for the network. There is a lot of flexibility in how we choose to break up the text and expose it to the network during training.\n",
    "We shall split the blog text into subsequences of 40 characters. We shall slide this window of 100 characters along the entire blog text, jumping 3 characters at every stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 2170111\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7oAAAEXCAYAAACDGTh0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05a14bda58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = len(text)\n",
    "\n",
    "char_frequency_counter = Counter()\n",
    "char_frequency_counter += Counter(text)\n",
    "\n",
    "char_frequency_dataframe = pd.DataFrame.from_dict(char_frequency_counter, orient='index').reset_index()\n",
    "char_frequency_dataframe = char_frequency_dataframe.rename(columns={'index':'characters', 0:'count'})\n",
    "order_of_chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z','|', '!', '\"', '#', '$', '%', '(', ')', '*', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', ' ']\n",
    "\n",
    "pyplot.figure(figsize=(16,4))\n",
    "pyplot.title('Distribution of characters in input data')\n",
    "pyplot.ylabel('Frequency [%]')\n",
    "ax = sns.barplot(x=char_frequency_dataframe[\"characters\"], y=char_frequency_dataframe[\"count\"], \n",
    "            order=order_of_chars, estimator=lambda y: (y / text_len) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must transform the list of input sequences into the form [samples, time steps, features] expected by an LSTM network. Next we need to rescale the integers to the range 0-to-1 to make the patterns easier to learn by the LSTM network that uses the sigmoid activation function by default. In order to do that, we shall one-hot encode the input sequences by creating a 3-dimensional matrix representation of sentences:\n",
    "* The 1st dimension is the total of all sentences (nb sequences).\n",
    "* The 2nd dimension is the length of each sentence, in our case 40\n",
    "* The 3rd dimension is the length of total vocab/unique characters, in our case 59.\n",
    "\n",
    "The output consists of a one-hot encoded 2-dimensional matrix. \n",
    "* The 1st dimension remains the same as input.\n",
    "* The 2nd dimension has the length of total vocab/unique characters.\n",
    "\n",
    "The output pair tells the next char for every input pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Total patterns 2170111\n",
      "Input vector shape (2170111, 40, 57)\n",
      "Output vector shape (2170111, 57)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print(\"Total patterns\", len(x))\n",
    "print(\"Input vector shape\", x.shape)\n",
    "print(\"Output vector shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(x.shape[1], x.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1]))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.pow(2.0, cross_entropy)\n",
    "    return perplexity\n",
    "\n",
    "optimizer = 'adam' # RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[perplexity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a model checkpoint\n",
    "filepath=\"weights-improvement.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Text with an LSTM Network\n",
    "\n",
    "The simplest way to use the Keras LSTM model to make predictions is to first start off with a seed sequence as input, generate the next character then update the seed sequence to add the generated character on the end and trim off the first character. This process is repeated for as long as we want to predict new characters (e.g. a sequence of 400 characters in length).\n",
    "\n",
    "We can pick a random input pattern as our seed sequence, then print generated characters as we generate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1736088 samples, validate on 434023 samples\n",
      "Epoch 1/60\n"
     ]
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "result = model.fit(x, y,\n",
    "          batch_size=512,\n",
    "          epochs=60,\n",
    "          validation_split=0.20,\n",
    "          shuffle=False,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(16,5))\n",
    "\n",
    "\n",
    "# sp1\n",
    "pyplot.subplot(121)\n",
    "pyplot.plot(result.history[\"loss\"])\n",
    "pyplot.plot(result.history[\"val_loss\"])\n",
    "pyplot.title('Train vs validation loss')\n",
    "pyplot.xlabel('no. of epochs')\n",
    "pyplot.ylabel('Loss score')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "\n",
    "# sp2\n",
    "pyplot.subplot(122)\n",
    "pyplot.plot(result.history[\"perplexity\"])\n",
    "pyplot.plot(result.history[\"val_perplexity\"])\n",
    "pyplot.title('Train vs validation perplexity')\n",
    "pyplot.xlabel('no. of epochs')\n",
    "pyplot.ylabel('Perplexity score')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "\n",
    "pyplot.tight_layout()\n",
    "\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
